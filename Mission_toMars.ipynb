{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "#from splinter.exceptions import ElementDoesNotExist\n",
    "import requests\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scaping NASA Mars SIte\n",
    "#########################################################\n",
    "#url = 'https://mars.nasa.gov/news/'\n",
    "url='https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = bs(response.text, 'lxml')\n",
    "\n",
    "results = soup.find_all('ul', class_=\"item_list\")\n",
    "newsTitle =soup.find(\"div\", class_=\"content_title\").text\n",
    "articles =soup.find(\"div\",class_=\"image_and_description_container\")\n",
    "news_p=articles.find(\"div\", class_=\"rollover_description_inner\").text\n",
    "\n",
    "\n",
    "print(newsTitle)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articalInfo=soup.find(\"div\",class_=\"list_text\").txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = soup.find_all('ul', class_=\"item_list\")\n",
    "articles =soup.find(\"div\",class_=\"image_and_description_container\")\n",
    "teaser=articles.find(\"div\", class_=\"rollover_description_inner\").text\n",
    "#articles =soup.find(\"div\",class_=\"list_text\")\n",
    "#articles =soup.find(\"div\",class_=\"content_title\")\n",
    "#link =articles.find(\"div\", class_=\"content_title\")\n",
    "#title=link['href']\n",
    "#article\n",
    "print(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#background-image: url('/spaceimages/images/wallpaper/PIA17924-1920x1200.jpg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teaser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#JPL Image Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_JPL='https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "response = requests.get(url_JPL)\n",
    "soup = bs(response.text, 'lxml')\n",
    "\n",
    "img_jpl = soup.find(\"img\", class_=\"thumb\")[\"src\"]\n",
    "featured_img_url=\"https://www.jpl.nasa.gov/\"+img_jpl\n",
    "print(featured_img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests #Using the 'requests' library to convert url to jpeg\n",
    "\n",
    "img_data = requests.get(featured_img_url).content\n",
    "with open('Mars_Featured.jpg', 'wb') as handler:\n",
    "    handler.write(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='Mars_Featured.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_jpl = soup.find(\"img\", class_=\"thumb\")[\"src\"]\n",
    "featured_img_url=\"https://www.jpl.nasa.gov/\"+img_jpl\n",
    "print(featured_img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<div class=\"js-tweet-text-container\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Twitter Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_Tweet='https://twitter.com/marswxreport?lang=en'\n",
    "response = requests.get(url_Tweet)\n",
    "soup = bs(response.text, 'lxml')\n",
    "\n",
    "wTweet_jpl = soup.find(\"div\", class_=\"js-tweet-text-container\")\n",
    "mars_Weather=wTweet_jpl.find('p').text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using Pandas to scrape Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://space-facts.com/mars/'\n",
    "### BEGIN SOLUTION\n",
    "marsTable = pd.read_html(url)\n",
    "df=marsTable[0]\n",
    "df.columns=['Mars Feature', 'Data']\n",
    "df.set_index('Mars Feature', inplace=True)\n",
    "df.to_html('mars_DataTable.html')\n",
    "mars_DataTable=df.to_html()\n",
    "mars_DataTable= mars_DataTable.replace('\\n', '')\n",
    "print(mars_DataTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scraping ... for Hemishphere information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "namesH=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ASC='https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "response = requests.get(url_ASC)\n",
    "soup = bs(response.text, 'lxml')\n",
    "hemisphere=[]\n",
    "hemis = soup.find_all(\"div\", class_=\"description\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h1=soup.h3.text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import bleach\n",
    "NumOfHem=soup.find_all('h3')\n",
    "clean=bleach.clean(NumOfHem, tags=[], strip=True)\n",
    "print(clean)\n",
    "NmOfHem = pd.DataFrame(eval(clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NumOfHem=soup.find_all('h3')\n",
    "m_tif=[]\n",
    "m_tif=pd.DataFrame(NumOfHem)\n",
    "m_tif.columns=['Hemisphere Name']\n",
    "m_tif.set_index('Hemisphere Name', inplace=True)\n",
    "m_tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in m_tif:\n",
    "    time.sleep(5)\n",
    "   # m_tiff=browser.find_by_tag('h3')\n",
    "   # m_tif=NumOfHem\n",
    "   # browser.click_link_by_partial_text(i)\n",
    "    browser.click_link_by_partial_text(i)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    src = soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "    \n",
    "    img_url ='https://astogeology.usgs.gov'+src\n",
    "    dictionary={\"title\":m_tiff, \"img_url\":img_url}\n",
    "    hemisphere.append(dictionary)\n",
    "    time.sleep(5)\n",
    "    browser.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hemisphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featured_img_url=\"https://www.jpl.nasa.gov/\"+img_jpl\n",
    "print(featured_img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of image urls\n",
    "hemisphere_image_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up splinter# Settin \n",
    "executable_path = {'executable_path':'./chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(url_ASC)\n",
    "\n",
    "# through pages\n",
    "time.sleep(5)\n",
    "browser.click_link_by_partial_text('Cerberus Hemisphere Enhanced')\n",
    "\n",
    "\n",
    "# BeautifulSoup object (parse with html.parser)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Store link\n",
    "Cerberus_Hemisphere_link = soup.find('div', 'downloads').a['href']\n",
    "\n",
    "# Create dict\n",
    "Cerberus_Hemisphere = {\n",
    "    \"title\": \"Cerberus Hemisphere Enhanced\",\n",
    "    \"img_url\": Cerberus_Hemisphere_link\n",
    "}\n",
    "\n",
    "# Append dict\n",
    "hemisphere_image_urls.append(Cerberus_Hemisphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up splinter\n",
    "executable_path = {'executable_path':'./chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(url_ASC)\n",
    "\n",
    "# through pages\n",
    "time.sleep(5)\n",
    "browser.click_link_by_partial_text('Schiaparelli Hemisphere Enhanced')\n",
    "\n",
    "\n",
    "# BeautifulSoup object (parse with html.parser)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Store link\n",
    "Schiaparelli_Hemisphere_link = soup.find('div', 'downloads').a['href']\n",
    "\n",
    "# Create dict\n",
    "Schiaparelli_Hemisphere = {\n",
    "    \"title\": \"Schiaparelli Hemisphere\",\n",
    "    \"img_url\": valles_link\n",
    "}\n",
    "\n",
    "# Append dict\n",
    "hemisphere_image_urls.append(Schiaparelli_Hemisphere_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up splinter\n",
    "executable_path = {'executable_path':'./chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(url_ASC)\n",
    "\n",
    "# through pages\n",
    "time.sleep(5)\n",
    "browser.click_link_by_partial_text('Syrtis Major Hemisphere Enhanced')\n",
    "\n",
    "\n",
    "# BeautifulSoup object (parse with html.parser)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Store link\n",
    "Syrtis_Major_Hemisphere_link = soup.find('div', 'downloads').a['href']\n",
    "\n",
    "# Create dict\n",
    "Syrtis_Major_Hemisphere = {\n",
    "    \"title\": \"Syrtis Major Hemisphere\",\n",
    "    \"img_url\": valles_link\n",
    "}\n",
    "\n",
    "# Append dict\n",
    "hemisphere_image_urls.append(Syrtis_Major_Hemisphere_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Syrtis_Major_Hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up splinter\n",
    "executable_path = {'executable_path':'./chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(url_ASC)\n",
    "\n",
    "# through pages\n",
    "time.sleep(5)\n",
    "browser.click_link_by_partial_text('Valles Marineris Hemisphere Enhanced')\n",
    "\n",
    "\n",
    "# BeautifulSoup object (parse with html.parser)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# Store link\n",
    "valles_link = soup.find('div', 'downloads').a['href']\n",
    "\n",
    "# Create dict\n",
    "valles_marineris = {\n",
    "    \"title\": \"Valles Marineris Hemisphere\",\n",
    "    \"img_url\": valles_link\n",
    "}\n",
    "\n",
    "# Append dict\n",
    "hemisphere_image_urls.append(valles_marineris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valles_marineris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
